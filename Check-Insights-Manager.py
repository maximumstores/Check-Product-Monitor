import time
import logging
from datetime import datetime
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import requests
import re
from urllib.parse import urlparse, parse_qs
import os
from threading import Lock
import ast
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill
from openpyxl.utils import get_column_letter
import telebot
import random
import pytz
import json
from gspread.exceptions import APIError
from bs4 import BeautifulSoup  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML, –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è
from datetime import datetime, timedelta
from openpyxl.utils import get_column_letter
import gspread_formatting as gf
from gspread_formatting import *
from google.oauth2.service_account import Credentials

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class APIRateLimiter:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API."""
    def __init__(self, max_requests, period):
        self.max_requests = max_requests
        self.period = period
        self.requests = []
        self.lock = Lock()

    def wait(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º, –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç."""
        with self.lock:
            now = time.time()
            # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø—Ä–æ—Å—ã
            self.requests = [r for r in self.requests if r > now - self.period]
            while len(self.requests) >= self.max_requests:
                next_request_time = self.requests[0] + self.period
                sleep_time = max(next_request_time - now, 0)
                logging.debug(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –°–ø–∏–º {sleep_time:.2f} —Å–µ–∫—É–Ω–¥.")
                time.sleep(sleep_time)
                now = time.time()
                self.requests = [r for r in self.requests if r > now - self.period]
            self.requests.append(now)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–µ—Ä–∞ –Ω–∞ 1 –∑–∞–ø—Ä–æ—Å –≤ —Å–µ–∫—É–Ω–¥—É
api_limiter = APIRateLimiter(max_requests=1, period=1)  # 1 –∑–∞–ø—Ä–æ—Å –≤ —Å–µ–∫—É–Ω–¥—É

def clean_urls(raw_value):
    if isinstance(raw_value, str):
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø–µ—Ä–µ–Ω–æ—Å–∞–º —Å—Ç—Ä–æ–∫, –∑–∞–ø—è—Ç—ã–º –∏ –ø—Ä–æ–±–µ–ª–∞–º
        urls = [url.strip() for url in re.split(r'[\n\r,]+', raw_value) if url.strip()]
    else:
        urls = raw_value if isinstance(raw_value, list) else []
    return urls



def retry_scrape(url, config, max_retries=5, initial_wait=2):
    wait_time = initial_wait
    for attempt in range(max_retries):
        try:
            api_limiter.wait()  # –ñ–¥–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
            product_info = scrape_amazon_product(url, config)
            if product_info:
                return product_info
        except requests.exceptions.RequestException as e:
            if hasattr(e, 'response') and e.response and e.response.status_code == 429:
                logging.warning(f"–û—à–∏–±–∫–∞ 429. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {wait_time} —Å–µ–∫—É–Ω–¥...")
                time.sleep(wait_time)
                wait_time *= 2  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è
            else:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è URL {url}: {str(e)}")
                break
    return None

def get_kyiv_time(timezone_str='Europe/Kiev'):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ –ö–∏–µ–≤–∞."""
    timezone = pytz.timezone(timezone_str)
    return datetime.now(timezone)


def get_next_slot(current_time, slots, timezone_str='Europe/Kiev'):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–ª–∏–∂–∞–π—à–∏–π —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ slots.

    :param current_time: –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è (datetime –æ–±—ä–µ–∫—Ç)
    :param slots: –°–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "HH:MM"
    :param timezone_str: –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å
    :return: datetime –æ–±—ä–µ–∫—Ç –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ—Ç–∞
    """
    timezone = pytz.timezone(timezone_str)
    today_slots = sorted(slots)
    for slot in today_slots:
        slot_time = datetime.strptime(slot, "%H:%M").time()
        slot_datetime = timezone.localize(datetime.combine(current_time.date(), slot_time))
        if slot_datetime > current_time:
            return slot_datetime
    # –ï—Å–ª–∏ –≤—Å–µ —Å–ª–æ—Ç—ã –Ω–∞ —Å–µ–≥–æ–¥–Ω—è —É–∂–µ –ø—Ä–æ—à–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π —Å–ª–æ—Ç –Ω–∞ –∑–∞–≤—Ç—Ä–∞
    first_slot = datetime.strptime(today_slots[0], "%H:%M").time()
    next_day = current_time + timedelta(days=1)
    return timezone.localize(datetime.combine(next_day.date(), first_slot))


def authorize_google_sheets(credentials_file):
    """
    –ê–≤—Ç–æ—Ä–∏–∑—É–µ—Ç—Å—è –≤ Google Sheets –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π –æ–±—ä–µ–∫—Ç.
    
    :param credentials_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö JSON
    :return: gspread.Client –æ–±—ä–µ–∫—Ç
    """
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    
    credentials = Credentials.from_service_account_file(credentials_file, scopes=scopes)
    client = gspread.authorize(credentials)
    logging.info("–£—Å–ø–µ—à–Ω–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–ª–∏—Å—å –≤ Google Sheets")
    return client


def load_config_from_sheets(client, spreadsheet_id):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ Google Sheets."""
    try:
        config_sheet = client.open_by_key(spreadsheet_id).worksheet('Config')
    except gspread.exceptions.WorksheetNotFound:
        logging.error("–õ–∏—Å—Ç 'Config' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ.")
        raise

    config = {}
    all_records = config_sheet.get_all_records()

    for record in all_records:
        key = record.get('Key', '')
        value = record.get('Value', '')

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º 'Key' –≤ —Å—Ç—Ä–æ–∫—É –∏ —É–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        if isinstance(key, str):
            key = key.strip()
        else:
            key = str(key).strip()

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º 'Value' –≤ —Å—Ç—Ä–æ–∫—É (–µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å—Ç—Ä–æ–∫–∞) –∏ —É–¥–∞–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏
        if isinstance(value, str):
            value = value.strip().strip('"').strip("'")
        else:
            value = str(value).strip()

        if not key:
            logging.warning("–ü—Ä–æ–ø—É—â–µ–Ω–∞ –∑–∞–ø–∏—Å—å —Å –ø—É—Å—Ç—ã–º –∫–ª—é—á–æ–º.")
            continue

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ URL-–ø–æ–ª–µ–π
        url_keys = [
            'product_urls', '1competitor_urls', '2competitor_urls', 
            '3competitor_urls', 'variation_urls', '1variation_urls', 
            '2variation_urls', '3variation_urls'
        ]

        if key in url_keys:
            # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —É–∂–µ —Å–ø–∏—Å–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if isinstance(value, list):
                config[key] = value
            else:
                # –ò–Ω–∞—á–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –Ω–∞ —Å–ø–∏—Å–æ–∫ URL
                config[key] = clean_urls(value)
            logging.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã URL –¥–ª—è '{key}': {config[key]}")
        elif key in ['update_time_hour', 'update_time_minute', 'batch_size']:
            try:
                config[key] = int(value)
                logging.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –¥–ª—è '{key}': {config[key]}")
            except ValueError:
                logging.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –¥–ª—è '{key}': {value}. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.")
                config[key] = 0
        elif key in ['min_acceptable_rating', 'price_change_threshold', 'coupon_threshold']:
            try:
                config[key] = float(value)
                logging.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π –¥–ª—è '{key}': {config[key]}")
            except ValueError:
                logging.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π –¥–ª—è '{key}': {value}. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.0.")
                config[key] = 0.0
        elif key in ['active_trade_slots', 'analysis_slots']:
            if value:
                # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ª–æ—Ç—ã –ø–æ –∑–∞–ø—è—Ç—ã–º –∏ –ø—Ä–æ–±–µ–ª–∞–º
                config[key] = [slot.strip() for slot in re.split(r'[,\s]+', value) if slot.strip()]
                logging.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ª–æ—Ç—ã –¥–ª—è '{key}': {config[key]}")
            else:
                config[key] = []
        else:
            config[key] = value
            logging.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è '{key}': {config[key]}")

    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–º–µ–Ω –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    competitor_1_name = config.get('competitor_1_name', '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç 1')
    competitor_2_name = config.get('competitor_2_name', '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç 2')
    competitor_3_name = config.get('competitor_3_name', '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç 3')

    if isinstance(competitor_1_name, str):
        competitor_1_name = competitor_1_name.strip()
    if isinstance(competitor_2_name, str):
        competitor_2_name = competitor_2_name.strip()
    if isinstance(competitor_3_name, str):
        competitor_3_name = competitor_3_name.strip()

    config['competitor_names'] = {
        '1': competitor_1_name,
        '2': competitor_2_name,
        '3': competitor_3_name
    }

    logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {json.dumps(config, indent=2, ensure_ascii=False)}")
    return config


def extract_asin(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ASIN –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ URL Amazon."""
    # –ü–∞—Ä—Å–∏–º URL
    parsed_url = urlparse(url)
    path = parsed_url.path

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è ASIN –∏–∑ –ø—É—Ç–∏ URL
    patterns = [
        r'/dp/([A-Z0-9]{10})',
        r'/gp/product/([A-Z0-9]{10})',
        r'/product/([A-Z0-9]{10})',
        r'/ASIN/([A-Z0-9]{10})',
        r'/gp/aw/d/([A-Z0-9]{10})',
        r'/gp/offer-listing/([A-Z0-9]{10})',
    ]
    for pattern in patterns:
        match = re.search(pattern, path)
        if match:
            asin = match.group(1)
            logging.debug(f"Extracted ASIN {asin} from URL path: {url}")
            return asin
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ ASIN –≤ –ø—É—Ç–∏, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
    query_params = parse_qs(parsed_url.query)
    if 'asin' in query_params:
        asin = query_params['asin'][0]
        logging.debug(f"Extracted ASIN {asin} from query parameters in URL: {url}")
        return asin
    # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ ASIN, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –µ–≥–æ –≤ URL —Ü–µ–ª–∏–∫–æ–º
    match = re.search(r'([A-Z0-9]{10})', url)
    if match:
        asin = match.group(1)
        logging.debug(f"Extracted ASIN {asin} from entire URL: {url}")
        return asin
    logging.warning(f"Could not extract ASIN from URL: {url}")
    return 'Not Found'

def is_valid_amazon_url(url):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º Amazon –ø—Ä–æ–¥—É–∫—Ç–æ–º."""
    parsed_url = urlparse(url)
    return parsed_url.netloc in ['www.amazon.com', 'amazon.com'] and '/dp/' in parsed_url.path
def clean_urls(raw_value):
    """
    –û—á–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É URL-–∞–¥—Ä–µ—Å–æ–≤, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª—é–±—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏,
    –≤–∫–ª—é—á–∞—è –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫, –∑–∞–ø—è—Ç—ã–µ, –ø—Ä–æ–±–µ–ª—ã, –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Å –∑–∞–ø—è—Ç—ã–º–∏ –∏ –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫.
    """
    if isinstance(raw_value, str):
        # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –∑–∞–ø—è—Ç—ã–µ, –∑–∞—Ç–µ–º —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–∞–ø—è—Ç—ã–º –∏ –ø—Ä–æ–±–µ–ª–∞–º
        urls = [url.strip() for url in re.split(r'[\n\r,]+', raw_value) if url.strip()]
    else:
        urls = raw_value if isinstance(raw_value, list) else []

    return urls

def write_hyperlinks(sheet, urls, start_row, column):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫–∏ –≤ Google Sheets, –∫–∞–∂–¥–∞—è —Å—Å—ã–ª–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ.
    
    :param sheet: –õ–∏—Å—Ç Google Sheets
    :param urls: –°–ø–∏—Å–æ–∫ URL-–∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏
    :param start_row: –ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏
    :param column: –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'A', 'B')
    """
    for i, url in enumerate(urls):
        asin = extract_asin(url)  # –ò–∑–≤–ª–µ–∫–∞–µ–º ASIN –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if asin != 'Not Found':
            # –°–æ–∑–¥–∞–µ–º –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫—É –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Å—ã–ª–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
            hyperlink_formula = f'=HYPERLINK("{url}", "{asin}")'
            cell = f'{column}{start_row + i}'  # –ö–∞–∂–¥–∞—è —Å—Å—ã–ª–∫–∞ –≤ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ
            sheet.update_acell(cell, hyperlink_formula)
        else:
            logging.warning(f"ASIN not found for URL: {url}")



def calculate_final_price(full_price, prime_price, coupon_discount):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ü–µ–Ω—É —Å —É—á—ë—Ç–æ–º —Å–∫–∏–¥–æ–∫ –∏ –∫—É–ø–æ–Ω–æ–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Å —Ñ–æ—Ä–º–∞—Ç–æ–º —Ü–µ–Ω—ã.
    """
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω –∏–∑ —Å—Ç—Ä–æ–∫ –≤ —á–∏—Å–ª–∞
        def price_to_float(price_str):
            if not price_str or price_str == "Not Found":
                return None
            return float(re.sub(r'[^\d.]', '', price_str))

        full_price_value = price_to_float(full_price)
        prime_price_value = price_to_float(prime_price)
        coupon_discount_value = float(re.sub(r'[^\d.]', '', str(coupon_discount).replace('%', ''))) if coupon_discount and coupon_discount != "Not Found" else 0.0

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º prime_price_value, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ, –∏–Ω–∞—á–µ full_price_value
        base_price = prime_price_value or full_price_value
        if base_price is None:
            logging.warning("Base price is not available for final price calculation.")
            return "Not Found"

        # –í—ã—á–∏—Å–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Ü–µ–Ω—É —Å —É—á—ë—Ç–æ–º –∫—É–ø–æ–Ω–∞
        discount_amount = base_price * (coupon_discount_value / 100)
        final_price_value = base_price - discount_amount

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Ü–µ–Ω—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç—Ä–æ–∫–∏
        return f"${final_price_value:.2f}"
    except ValueError as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ü–µ–Ω—ã: {str(e)}")
        return "Not Found"

def calculate_discount_percent(full_price, final_price):
    """–í—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç —Å–∫–∏–¥–∫–∏."""
    try:
        if full_price == "Not Found" or final_price == "Not Found":
            return "–ù–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ"
        
        full_price_value = float(re.sub(r'[^\d.]', '', str(full_price)))
        final_price_value = float(re.sub(r'[^\d.]', '', str(final_price)))
        
        if full_price_value == 0:
            return "N/A"
        
        discount_percent_value = (full_price_value - final_price_value) / full_price_value * 100
        return f"{discount_percent_value:.2f}%"
    except ValueError:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å–∫–∏–¥–∫–∏ —Å Full Price: {full_price} –∏ Final Price: {final_price}")
        return "–ù–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ"
def extract_price(price_data):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞.
    
    :param price_data: –î–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–µ –∏–∑ JSON-–æ—Ç–≤–µ—Ç–∞.
    :return: –°—Ç—Ä–æ–∫–∞ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º —Ü–µ–Ω—ã –∏–ª–∏ "Not Found".
    """
    logging.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö: {price_data}")
    
    if not price_data or price_data == "Not Found":
        logging.warning("–¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞.")
        return "Not Found"
    
    if isinstance(price_data, dict):
        # –í–æ–∑–º–æ–∂–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è —Ü–µ–Ω—ã
        possible_keys = ['raw', 'display_price', 'value', 'price']
        for key in possible_keys:
            if key in price_data:
                extracted_price = price_data[key]
                logging.debug(f"–ù–∞–π–¥–µ–Ω–æ '{key}': {extracted_price}")
                if isinstance(extracted_price, (int, float)):
                    return f"${extracted_price:.2f}"
                elif isinstance(extracted_price, str):
                    match = re.search(r'\$?\d+(\.\d+)?', extracted_price)
                    if match:
                        return match.group()
        logging.warning("–¶–µ–Ω–∞ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–∑ —Å–ª–æ–≤–∞—Ä—è.")
    elif isinstance(price_data, (int, float)):
        logging.debug(f"–¶–µ–Ω–∞ –∫–∞–∫ —á–∏—Å–ª–æ: {price_data}")
        return f"${price_data:.2f}"
    elif isinstance(price_data, str):
        match = re.search(r'\$?\d+(\.\d+)?', price_data)
        if match:
            logging.debug(f"–¶–µ–Ω–∞ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞: {match.group()}")
            return match.group()
        else:
            logging.warning("–¶–µ–Ω–∞ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–∑ —Å—Ç—Ä–æ–∫–∏.")
    
    logging.warning("–¶–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    return "Not Found"



def extract_coupon(coupon_data):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∫—É–ø–æ–Ω–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞."""
    logging.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫—É–ø–æ–Ω–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö: {coupon_data}")
    if isinstance(coupon_data, (int, float)):
        return f"{coupon_data}%"
    elif isinstance(coupon_data, str):
        coupon_match = re.search(r'\d+(?:\.\d{1,2})?', coupon_data)
        if coupon_match:
            return f"{float(coupon_match.group())}%"
    return 'Not Found'

def extract_bsr(product_data):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç Best Sellers Rank (BSR) –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞."""
    logging.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ BSR –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞: {product_data}")
    bsr_value = 'Not Found'
    bsr_locations = [
        'best_sellers_rank', 'bsr', 'bestsellers_rank',
        'bestseller_rank', 'sales_rank', 'rank'
    ]
    
    for location in bsr_locations:
        bsr_data = product_data.get(location)
        if bsr_data:
            logging.debug(f"–ù–∞–π–¥–µ–Ω–æ BSR –≤ '{location}': {bsr_data}")
            
            if isinstance(bsr_data, list):
                for item in bsr_data:
                    if isinstance(item, dict):
                        rank = item.get('rank') or item.get('value')
                        if rank:
                            bsr_value = str(rank).replace(',', '').split()[0]
                            break
                    elif isinstance(item, str):
                        match = re.search(r'#?([\d,]+)', item)
                        if match:
                            bsr_value = match.group(1).replace(',', '')
                            break
            elif isinstance(bsr_data, dict):
                rank = bsr_data.get('rank') or bsr_data.get('value')
                if rank:
                    bsr_value = str(rank).replace(',', '').split()[0]
            elif isinstance(bsr_data, str):
                match = re.search(r'#?([\d,]+)', bsr_data)
                if match:
                    bsr_value = match.group(1).replace(',', '')
            elif isinstance(bsr_data, (int, float)):
                bsr_value = str(int(bsr_data))
            
            if bsr_value != 'Not Found':
                break

    logging.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π BSR: {bsr_value}")
    return bsr_value

def extract_data_from_json(response_json, asin, is_variation=False):
    logging.debug("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON.")
    try:
        product_data = response_json['results'][0]['content']
        logging.debug(f"–ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç–∞: {json.dumps(product_data, indent=2)}")

        title = product_data.get('title', 'Not Found')
        rating = product_data.get('rating', 'Not Found')
        reviews_count = product_data.get('reviews_count') or product_data.get('review_count', 'Not Found')
        brand = product_data.get('brand', 'Not Found')
        bsr = extract_bsr(product_data)

        price = extract_price(product_data.get('price'))
        prime_price = extract_price(product_data.get('prime_offer_price'))  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –∫–ª—é—á
        title_price = extract_price(product_data.get('title_price'))
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ List Price –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ price_strikethrough
        list_price = product_data.get('price_strikethrough', 'Not Found')
        logging.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π List Price: {list_price}")

        coupon = extract_coupon(product_data.get('coupon'))
        final_price = calculate_final_price(price, prime_price or price, coupon)
        discount_percent = calculate_discount_percent(price, final_price)

        product_info = {
            "ASIN": asin,
            "Title": title,
            "Price": price,
            "Prime Price": prime_price or price,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º prime_price
            "Title Price": title_price,
            "List Price": list_price,
            "Coupon Discount": coupon,
            "Final Price": final_price,
            "Discount Percent": discount_percent,
            "Rating": rating,
            "Number of Reviews": reviews_count,
            "BSR": bsr,
            "Brand": brand,
            "Scrape Date": get_kyiv_time().strftime("%d.%m.%Y"),
            "URL": product_data.get('url', 'Not Found')
        }

        logging.debug(f"Prime Offer Price: {prime_price}")  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

        logging.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ASIN {product_info['ASIN']}: {json.dumps(product_info, indent=2)}")
        return product_info

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON: {str(e)}")
        return None



def extract_list_price(product_data):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç List Price –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞.
    
    :param product_data: –î–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥—É–∫—Ç–µ –∏–∑ JSON.
    :return: List Price –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ "Not Available".
    """
    logging.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ List Price –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞: {json.dumps(product_data, indent=2)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è List Price
    possible_keys = ['list_price', 'price_strikethrough', 'was_price', 'original_price', 'old_price']
    
    for key in possible_keys:
        list_price = product_data.get(key)
        if list_price:
            logging.info(f"–ù–∞–π–¥–µ–Ω List Price –ø–æ–¥ –∫–ª—é—á–æ–º '{key}': {list_price}")
            
            if isinstance(list_price, dict):
                # –ï—Å–ª–∏ List Price - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∑–Ω–∞—á–µ–Ω–∏–µ
                for subkey in ['value', 'amount', 'price', 'raw']:
                    if subkey in list_price:
                        return format_price(list_price[subkey])
            elif isinstance(list_price, (int, float)):
                return format_price(list_price)
            elif isinstance(list_price, str):
                # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                match = re.search(r'\$?(\d+(?:\.\d{2})?)', list_price)
                if match:
                    return format_price(float(match.group(1)))
    
    # –ï—Å–ª–∏ List Price –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤—ã–≤–æ–¥–∏–º –≤—Å–µ –∫–ª—é—á–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    logging.warning(f"List Price –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏: {list(product_data.keys())}")
    return "Not Available"




def format_price(price):
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ü–µ–Ω—É –≤ —Å—Ç—Ä–æ–∫—É —Å –¥–≤—É–º—è –∑–Ω–∞–∫–∞–º–∏ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π."""
    return f"${price:.2f}" if isinstance(price, (int, float)) else str(price)


def scrape_amazon_product(url, config, is_variation=False):
    """–°–∫—Ä–∞–ø–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥—É–∫—Ç–µ —Å Amazon —á–µ—Ä–µ–∑ Oxylabs."""
    if not url.startswith('http'):
        logging.error(f"Invalid URL: {url}")
        return None

    asin = extract_asin(url)
    if asin == 'Not Found':
        logging.error(f"ASIN not found in URL: {url}")
        return None

    payload = {
        'source': 'amazon',
        'url': url,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π URL –≤–º–µ—Å—Ç–æ ASIN
        'parse': True
    }

    logging.debug(f"Payload: {payload}")

    max_retries = 3
    for attempt in range(max_retries):
        try:
            api_limiter.wait()

            oxylabs_username = config.get('oxylabs_username', '').strip()
            oxylabs_password = config.get('oxylabs_password', '').strip()

            if not oxylabs_username or not oxylabs_password:
                logging.error("Oxylabs credentials are missing in the configuration")
                return None

            logging.info(f"Sending request to Oxylabs for ASIN: {asin}")

            response = requests.post(
                'https://realtime.oxylabs.io/v1/queries',
                auth=(oxylabs_username, oxylabs_password),
                json=payload,
                timeout=30
            )

            logging.debug(f"Received response: {response.status_code} - {response.text}")

            if response.status_code == 204:
                logging.error(f"No Content for ASIN {asin}")
                return None

            if response.status_code != 200:
                logging.error(f"Non-200 response from Oxylabs: {response.status_code}")
                continue

            try:
                response_json = response.json()
                logging.debug(f"Received JSON for ASIN {asin}: {json.dumps(response_json, indent=2, ensure_ascii=False)}")  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ JSON-–æ—Ç–≤–µ—Ç–∞
            except ValueError:
                logging.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –¥–ª—è ASIN {asin}")
                continue

            if 'error' in response_json:
                logging.error(f"Error from Oxylabs for ASIN {asin}: {response_json['error']}")
                return None

            product_info = extract_data_from_json(response_json, asin, is_variation=is_variation)
            if product_info:
                logging.info(f"Successfully scraped data for ASIN: {asin}")
                logging.debug(f"Product Info: {product_info}")
                return product_info
            else:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è ASIN {asin}")
        except requests.exceptions.RequestException as e:
            logging.error(f"Request exception for ASIN {asin}: {str(e)}")
            if attempt < max_retries - 1:
                wait_time = 5 * (attempt + 1)
                logging.info(f"Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                logging.error(f"Failed to retrieve data for ASIN {asin} after {max_retries} attempts.")
                return None

    return None


def send_telegram_message(bot, chat_id, message):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram."""
    try:
        bot.send_message(chat_id, message)
        logging.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram")
    except Exception as e:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram: {str(e)}")

def check_product_notifications(product_info, min_rating, price_threshold, coupon_threshold):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å–ª–æ–≤–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π."""
    notifications = []

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞
    rating = product_info.get("Rating", "Not Found")
    if rating != "Not Found":
        try:
            rating_value = float(rating)
            if rating_value < min_rating:
                notifications.append(f"‚ö†Ô∏è –ù–∏–∑–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {rating} –∑–≤–µ–∑–¥ –¥–ª—è ASIN {product_info['ASIN']}")
        except ValueError:
            notifications.append(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –¥–ª—è ASIN {product_info['ASIN']}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
    full_price = product_info.get("Price", "Not Found")
    prime_price = product_info.get("Prime Price", "Not Found")
    if full_price != "Not Found" and prime_price != "Not Found":
        try:
            full_price_value = float(re.sub(r'[^\d.]', '', str(full_price))) if isinstance(full_price, (str, float)) else None
            prime_price_value = float(re.sub(r'[^\d.]', '', str(prime_price))) if isinstance(prime_price, (str, float)) else None
            if full_price_value and prime_price_value:
                price_diff_percent = abs(full_price_value - prime_price_value) / full_price_value * 100
                if price_diff_percent >= price_threshold:
                    notifications.append(f"üí∞ –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –¥–ª—è ASIN {product_info['ASIN']}: Full ${full_price_value:.2f}, Prime ${prime_price_value:.2f}")
        except ValueError:
            notifications.append(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ü–µ–Ω–∞ –¥–ª—è ASIN {product_info['ASIN']}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—É–ø–æ–Ω–∞
    coupon_discount = product_info.get("Coupon Discount", "Not Found")
    if coupon_discount != "Not Found":
        try:
            coupon_value = float(re.sub(r'[^\d.]', '', str(coupon_discount).replace('%', '')))
            if coupon_value >= coupon_threshold:
                notifications.append(f"üè∑Ô∏è –ë–æ–ª—å—à–æ–π –∫—É–ø–æ–Ω –¥–ª—è ASIN {product_info['ASIN']}: {coupon_value}%")
        except ValueError:
            notifications.append(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å–∫–∏–¥–∫–∞ –∫—É–ø–æ–Ω–∞ –¥–ª—è ASIN {product_info['ASIN']}")

    return notifications


def update_monitoring_sheet(spreadsheet, data, current_time_slot, config):
    sheet_name = "SS+Sox"  # –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞ –≤ Google Sheets
    try:
        sheet = spreadsheet.worksheet(sheet_name)
    except gspread.exceptions.WorksheetNotFound:
        logging.error(f"–õ–∏—Å—Ç '{sheet_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü–µ.")
        return

    header = [
        "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ", "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã", "–î–∞–Ω–Ω—ã–µ"
    ] + config.get('active_trade_slots', []) + ["–ó–æ–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞"] + config.get('analysis_slots', [])

    header = [slot.strip() if isinstance(slot, str) else slot for slot in header]

    logging.debug(f"–¢–µ–∫—É—â–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–ª–æ—Ç: '{current_time_slot}'")
    logging.debug(f"–ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã: {header}")

    value_ranges = [{
        'range': f'{sheet_name}!A1',
        'values': [header]
    }]

    start_row = 3
    current_row = start_row

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM-DD HH:MM:SS" –≤ –∫–∏–µ–≤—Å–∫–æ–º —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ
    current_time = get_kyiv_time().strftime("%Y-%m-%d %H:%M:%S")

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ 2-—é —Å—Ç—Ä–æ–∫—É –≤ –∫–æ–ª–æ–Ω–∫—É "–î–∞–Ω–Ω—ã–µ"
    time_notation = f'{sheet_name}!C2'  # –Ø—á–µ–π–∫–∞ C2 (—Å—Ç—Ä–æ–∫–∞ 2, –∫–æ–ª–æ–Ω–∫–∞ "–î–∞–Ω–Ω—ã–µ")
    value_ranges.append({
        'range': time_notation,
        'values': [[current_time]]  # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
    })


    parameters = ["BSR", "Number of Reviews", "Rating", "Price"]

    companies = [
        ("product_urls", "Merino.tech. (–ú—ã)"),
        ("1competitor_urls", config.get('competitor_1_name', 'Competitor 1').strip()),
        ("2competitor_urls", config.get('competitor_2_name', 'Competitor 2').strip()),
    ]
    companies = [(section, name) for section, name in companies if name]

    data_to_write = []

    data_to_write.append(["Parent ASIN"])
    current_row += 1

    asin_row_mapping_parent = {}

    for param in parameters:
        data_to_write.append([param])  
        current_row += 1

        for section, company_name in companies:
            urls = config.get(section, [])
            if urls:
                for url in urls:
                    asin = extract_asin(url)
                    logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ URL: {url}, –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π ASIN: {asin}, –∫–æ–º–ø–∞–Ω–∏—è: {company_name}")

                    product_info = next((prod for prod in data.get(company_name, []) if prod.get('ASIN') == asin), {})

                    if not product_info:
                        asin_display = 'Not Found'
                        param_value = None
                    else:
                        asin_display = asin
                        param_value = product_info.get(param, None)
                        if isinstance(param_value, str) and param_value.lower() == "not found":
                            param_value = None

                    hyperlink_formula = f'=HYPERLINK("{url}", "{asin_display}")' if asin_display != "Not Found" else asin_display
                    data_to_write.append([company_name, hyperlink_formula, param_value])
                    asin_row_mapping_parent[(company_name, asin, param)] = current_row
                    current_row += 1

                data_to_write.append([''])
                current_row += 1

    data_to_write.append(["Variations ASIN"])
    current_row += 1

    variations_sections = [
        ("variation_urls", "Merino.tech. (–ú—ã)"),
        ("1variation_urls", config.get('competitor_1_name', 'Competitor 1').strip()),
        ("2variation_urls", config.get('competitor_2_name', 'Competitor 2').strip()),
    ]
    variations_sections = [(section, name) for section, name in variations_sections if name]

    price_types = ["Price", "List Price", "Prime Price"]  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ "Prime Price" –≤–∫–ª—é—á—ë–Ω

    asin_row_mapping_variations = {}
    average_row_mapping = {}

    for price_type in price_types:
        data_to_write.append([price_type])
        current_row += 1

        for section, company_name in variations_sections:
            urls = config.get(section, [])
            if urls:
                temp_asin_rows = []
                num_variations = 0

                formula_row = current_row  

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã –≤ –∫–æ–ª–æ–Ω–∫—É "–î–∞–Ω–Ω—ã–µ"
                data_to_write.append([company_name, "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞", ""])  
                current_row += 1

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ñ–æ—Ä–º—É–ª—ã —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã
                average_row_number = current_row - 1
                average_row_mapping[(company_name, price_type)] = average_row_number

                for url in urls:
                    asin = extract_asin(url)
                    logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞—Ä–∏–∞—Ü–∏–∏ URL: {url}, –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π ASIN: {asin}, –∫–æ–º–ø–∞–Ω–∏—è: {company_name}")

                    product_info = next((prod for prod in data.get(company_name, []) if prod.get('ASIN') == asin), {})

                    if not product_info:
                        price_value = None
                    else:
                        price_value = product_info.get(price_type, None)
                        if isinstance(price_value, str) and price_value.lower() == "not found":
                            price_value = None

                    hyperlink_formula = f'=HYPERLINK("{url}", "{asin}")' if asin != "Not Found" else asin

                    if isinstance(price_value, (int, float)):
                        price_display = f"${price_value:.2f}"
                    elif isinstance(price_value, str):
                        price_display = price_value
                    else:
                        price_display = None

                    temp_asin_rows.append([company_name, hyperlink_formula, price_display])
                    asin_row_mapping_variations[(company_name, asin, price_type)] = current_row
                    current_row += 1
                    num_variations += 1

                data_to_write.extend(temp_asin_rows)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–æ—Ä–º—É–ª—É —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã –≤ –∫–æ–ª–æ–Ω–∫–µ "–î–∞–Ω–Ω—ã–µ" (C-–∫–æ–ª–æ–Ω–∫–∞)
                first_price_row = formula_row + 1
                last_price_row = formula_row + num_variations
                price_range = f"C{first_price_row}:C{last_price_row}"
                average_formula = f'=AVERAGE(FILTER({price_range}, {price_range}<>""))'

                data_to_write[formula_row - start_row][2] = average_formula

                data_to_write.append([''])
                current_row += 1

    end_row = start_row + len(data_to_write) - 1
    range_notation = f'{sheet_name}!A{start_row}:C{end_row}'

    value_ranges.append({
        'range': range_notation,
        'values': data_to_write
    })

    if current_time_slot and current_time_slot in header:
        slot_column = header.index(current_time_slot) + 1  
        logging.info(f"–î–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –∑–∞–ø–∏—Å–∞–Ω—ã –≤ –∫–æ–ª–æ–Ω–∫—É '{current_time_slot}' (—Å—Ç–æ–ª–±–µ—Ü {slot_column})")
    else:
        logging.info("–¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Å–ª–æ—Ç–∞–º–∏, –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –∑–∞–ø–∏—Å–∞–Ω—ã –≤ –∫–æ–ª–æ–Ω–∫—É '–î–∞–Ω–Ω—ã–µ'")
        slot_column = header.index("–î–∞–Ω–Ω—ã–µ") + 1

    column_letter = get_column_letter(slot_column)

    slot_updates = []

    def find_product_info(all_data, company_name, asin):
        products = all_data.get(company_name, [])
        for prod in products:
            if prod.get('ASIN') == asin:
                return prod
        return None

    for (company_name, asin, param), row_number in asin_row_mapping_parent.items():
        product_info = find_product_info(data, company_name, asin)
        if product_info:
            value = product_info.get(param, None)
            if isinstance(value, str) and value.lower() == "not found":
                value = None  
            cell_notation = f'{sheet_name}!{column_letter}{row_number}'
            slot_updates.append({
                'range': cell_notation,
                'values': [[value]]
            })

    for (company_name, asin, price_type), row_number in asin_row_mapping_variations.items():
        product_info = find_product_info(data, company_name, asin)
        if product_info:
            price_value = product_info.get(price_type, None)
            if isinstance(price_value, str) and price_value.lower() == "not found":
                price_value = None  
            elif isinstance(price_value, (int, float)):
                price_value = f"${price_value:.2f}"
            cell_notation = f'{sheet_name}!{column_letter}{row_number}'
            slot_updates.append({
                'range': cell_notation,
                'values': [[price_value]]
            })

    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª—ã —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Å–ª–æ—Ç–µ
    for (company_name, price_type), row_number in average_row_mapping.items():
        variation_rows = [row_num for (comp, asin, ptype), row_num in asin_row_mapping_variations.items()
                          if comp == company_name and ptype == price_type]

        if variation_rows:
            first_row = min(variation_rows)
            last_row = max(variation_rows)
            slot_column_letter = column_letter  

            price_range = f'{slot_column_letter}{first_row}:{slot_column_letter}{last_row}'

            average_formula = f'=AVERAGE(FILTER({price_range}, {price_range}<>""))'

            cell_notation = f'{sheet_name}!{slot_column_letter}{row_number}'

            slot_updates.append({
                'range': cell_notation,
                'values': [[average_formula]]
            })

    value_ranges.extend(slot_updates)

    try:
        data_body = {
            'value_input_option': 'USER_ENTERED',
            'data': value_ranges
        }
        spreadsheet.values_batch_update(data_body)
        logging.info("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ Google Sheets.")
    except APIError as e:
        logging.error(f"–û—à–∏–±–∫–∞ API –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Google Sheets: {str(e)}")
        retry_delay = 60  
        logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ {retry_delay} —Å–µ–∫—É–Ω–¥...")
        time.sleep(retry_delay)
        try:
            spreadsheet.values_batch_update(data_body)
            logging.info("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ Google Sheets –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏.")
        except Exception as e2:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å Google Sheets –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏: {str(e2)}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Google Sheets: {str(e)}")







def extract_reviews_count(product_data):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–∞."""
    reviews_count = 'Not Found'
    possible_keys = ['reviews_count', 'rating_count', 'ratings_total', 'review_count']
    
    for key in possible_keys:
        if key in product_data:
            reviews_count = product_data[key]
            break
    
    if reviews_count != 'Not Found':
        if isinstance(reviews_count, str):
            reviews_count = re.sub(r'[^\d]', '', reviews_count)
        
        try:
            reviews_count = int(reviews_count)
        except ValueError:
            reviews_count = 'Not Found'
   
    logging.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤: {reviews_count}")
    return reviews_count

def create_xlsx_report(data, current_time_str):
    """–°–æ–∑–¥–∞–Ω–∏–µ XLSX –æ—Ç—á–µ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö."""
    try:
        wb = Workbook()
        ws = wb.active
        ws.title = "Product Report"

        # –°—Ç–∏–ª–∏
        header_font = Font(bold=True)
        header_fill = PatternFill(start_color="CCCCCC", end_color="CCCCCC", fill_type="solid")
        bold_blue_font = Font(bold=True, color="0000FF")  # –ñ–∏—Ä–Ω—ã–π –∏ —Å–∏–Ω–∏–π —Ü–≤–µ—Ç –¥–ª—è –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã—Ö ASIN

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        ws['A1'] = f"Product Report - {current_time_str}"
        ws['A1'].font = Font(bold=True, size=14)
        ws.merge_cells('A1:N1')  # –†–∞—Å—à–∏—Ä–∏–ª –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
        headers = [
            "Company", "ASIN", "Title", "Full Price", "Prime Price", 
            "Avg List Price", "Avg Title Price", "Avg Prime Price",
            "Rating", "Number of Reviews", "Coupon Discount", 
            "Final Price", "Discount Percent", "Variations Count"
        ]
        for col, header in enumerate(headers, start=1):
            cell = ws.cell(row=2, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill

        # –î–∞–Ω–Ω—ã–µ
        row = 3
        for company, products in data.items():
            for product in products:
                ws.cell(row=row, column=1, value=company)
                asin_cell = ws.cell(row=row, column=2, value=product.get('ASIN', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ'))
                asin = product.get('ASIN', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ')
                if asin != '–ù–µ –Ω–∞–π–¥–µ–Ω–æ':
                    asin_cell.hyperlink = f"https://www.amazon.com/dp/{asin}"
                    asin_cell.font = bold_blue_font  # –°–¥–µ–ª–∞—Ç—å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–º ASIN –∂–∏—Ä–Ω—ã–º –∏ —Å–∏–Ω–∏–º
                ws.cell(row=row, column=3, value=product.get('Title', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ'))
                ws.cell(row=row, column=4, value=product.get('Price', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ'))
                ws.cell(row=row, column=5, value=product.get('Prime Price', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ'))
                ws.cell(row=row, column=6, value=product.get('List Price', 'Not Found'))
                ws.cell(row=row, column=7, value=product.get('Sale Price', 'Not Found'))
                ws.cell(row=row, column=8, value=product.get('Prime Price', 'Not Found'))
                ws.cell(row=row, column=9, value=product.get('Rating', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ'))
                ws.cell(row=row, column=10, value=product.get('Number of Reviews', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ'))
                ws.cell(row=row, column=11, value=product.get('Coupon Discount', 'Not Found'))
                ws.cell(row=row, column=12, value=product.get('Final Price', 'Not Found'))
                ws.cell(row=row, column=13, value=product.get('Discount Percent', 'Not Found'))
                ws.cell(row=row, column=14, value=product.get('Variations Count', 'Not Found'))
                row += 1

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤
        for col in ws.columns:
            max_length = 0
            column = col[0].column  # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å—Ç–æ–ª–±—Ü–∞
            column_letter = get_column_letter(column)
            for cell in col:
                if cell.value:
                    cell_length = len(str(cell.value))
                    if cell_length > max_length:
                        max_length = cell_length
            adjusted_width = (max_length + 2)
            ws.column_dimensions[column_letter].width = adjusted_width

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        filename = f"product_report_{current_time_str.replace(':', '_')}.xlsx"
        wb.save(filename)
        return filename
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ XLSX –æ—Ç—á–µ—Ç–∞: {str(e)}")
        return None

def send_telegram_notification(config, current_time_str, data):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∏ –æ—Ç—á–µ—Ç–∞ –≤ Telegram."""
    bot = telebot.TeleBot(config.get('telegram_bot_token', ''))
    chat_id = config.get('telegram_chat_id', '')
    if not chat_id:
        logging.error("Telegram chat_id –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.")
        return

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    message = f"–û—Ç—á–µ—Ç –∑–∞ {current_time_str}\n\n"
    for company, products in data.items():
        message += f"{company}:\n"
        for product in products:
            message += f" ASIN: {product['ASIN']}\n"
            message += f" –¶–µ–Ω–∞: {product.get('Price', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ')}\n"
            message += f" –†–µ–π—Ç–∏–Ω–≥: {product.get('Rating', '–ù–µ –Ω–∞–π–¥–µ–Ω–æ')}\n\n"

    # –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    send_telegram_message(bot, chat_id, message)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ XLSX —Ñ–∞–π–ª–∞
    xlsx_filename = create_xlsx_report(data, current_time_str)
    if xlsx_filename:
        try:
            with open(xlsx_filename, 'rb') as report_file:
                bot.send_document(chat_id, report_file)
            logging.info("–û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram.")
        except Exception as e:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á–µ—Ç –≤ Telegram: {str(e)}")
        finally:
            if os.path.exists(xlsx_filename):
                os.remove(xlsx_filename)

def round_time_to_nearest_slot(current_time_str, active_trade_slots, analysis_slots):
    """–û–∫—Ä—É–≥–ª—è–µ—Ç —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Å–ª–æ—Ç–∞."""
    all_slots = active_trade_slots + analysis_slots
    if not all_slots:
        logging.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
        return None

    current_time_minutes = int(current_time_str.split(":")[0]) * 60 + int(current_time_str.split(":")[1])
    
    nearest_slot = min(all_slots, key=lambda slot: abs(current_time_minutes - (int(slot.split(":")[0]) * 60 + int(slot.split(":")[1]))))
    return nearest_slot

def update_google_sheets(current_results, spreadsheet_id, config, current_time_str, credentials_file):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Google Sheets –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ current_results."""
    try:
        client = authorize_google_sheets(credentials_file)
        spreadsheet = client.open_by_key(spreadsheet_id)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM
        current_time_formatted = current_time_str.split(' ')[1][:5]
        
        all_slots = config.get('active_trade_slots', []) + config.get('analysis_slots', [])
        
        if current_time_formatted in all_slots:
            current_time_slot = current_time_formatted
        else:
            current_time_slot = None  # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Å–ª–æ—Ç–∞–º–∏

        update_monitoring_sheet(spreadsheet, current_results, current_time_slot, config)

    except APIError as e:
        logging.error(f"–û—à–∏–±–∫–∞ API –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Google Sheets: {str(e)}")

def gather_product_data(config, competitor_urls, competitor_variation_urls):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
    current_results = {
        "Merino.tech. (–ú—ã)": [],
        "Merino Protect": [],
        "METARINO": [],
    }

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (Parent ASIN)
    logging.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–æ–¥—É–∫—Ç–∞–º Merino.tech (Parent ASIN).")
    for url in config.get('product_urls', []):
        logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ Parent ASIN –ø–æ URL: {url}")
        try:
            product_info = scrape_amazon_product(url, config)
            if product_info:
                logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ (Parent ASIN): {url}")
                current_results["Merino.tech. (–ú—ã)"].append(product_info)
            else:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ (Parent ASIN): {url}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Parent ASIN –ø–æ –ø—Ä–æ–¥—É–∫—Ç—É {url}: {str(e)}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞—Ä–∏–∞—Ü–∏–π –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (Variation ASIN)
    logging.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–∞—Ä–∏–∞—Ü–∏—è–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤ Merino.tech (Variation ASIN).")
    for var_url in config.get('variation_urls', []):
        logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ Variation ASIN –ø–æ URL: {var_url}")
        try:
            variation_info = scrape_amazon_product(var_url, config, is_variation=True)
            if variation_info:
                logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–∞ (Variation ASIN): {var_url}")
                current_results["Merino.tech. (–ú—ã)"].append(variation_info)
            else:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–∞: {var_url}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Variation ASIN –ø–æ –ø—Ä–æ–¥—É–∫—Ç—É {var_url}: {str(e)}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    logging.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º.")
    for competitor_name, urls in competitor_urls.items():
        for url in urls:
            logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –ø–æ URL: {url}")
            try:
                product_info = scrape_amazon_product(url, config)
                if product_info:
                    logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ {competitor_name}: {url}")
                    current_results.setdefault(competitor_name, []).append(product_info)
                else:
                    logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ {competitor_name}: {url}")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ {competitor_name} ({url}): {str(e)}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞—Ä–∏–∞—Ü–∏–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    logging.info("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–∞—Ä–∏–∞—Ü–∏—è–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤.")
    for competitor_name, var_urls in competitor_variation_urls.items():
        for var_url in var_urls:
            logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –ø–æ URL: {var_url}")
            try:
                variation_info = scrape_amazon_product(var_url, config, is_variation=True)
                if variation_info:
                    logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ {competitor_name}: {var_url}")
                    current_results.setdefault(competitor_name, []).append(variation_info)
                else:
                    logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ {competitor_name}: {var_url}")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ {competitor_name} ({var_url}): {str(e)}")

    return current_results


def find_credentials_file():
    """–ü—ã—Ç–∞–µ—Ç—Å—è –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –≤–æ–∑–º–æ–∂–Ω—ã–º –ø—É—Ç—è–º."""
    possible_paths = [
        os.path.join(os.path.expanduser('~'), 'Downloads', 'maximumstores53-24d4ef8c1298.json'),
        os.path.join(os.getcwd(), 'maximumstores53-24d4ef8c1298.json'),
        'maximumstores53-24d4ef8c1298.json'
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            logging.info(f"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {path}")
            return path

    logging.error("–§–∞–π–ª —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ –æ–¥–Ω–æ–º –∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π.")
    return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Google Sheets
    credentials_file = find_credentials_file()
    if not credentials_file:
        logging.critical("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        return

    # ID —Ç–∞–±–ª–∏—Ü—ã Google Sheets
    spreadsheet_id = '1ibuYnN9WeRZdHUqoiU2jFLez59fm5Gfgzeyvq7M4EaI'

    # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    try:
        client = authorize_google_sheets(credentials_file)
        config = load_config_from_sheets(client, spreadsheet_id)
    except Exception as e:
        logging.critical(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {e}")
        return

    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    logging.info(f"Product URLs after loading config: {config.get('product_urls', [])}")
    logging.info(f"Variation URLs after loading config: {config.get('variation_urls', [])}")
    logging.info(f"Competitor 1 URLs after loading config: {config.get('1competitor_urls', [])}")
    logging.info(f"Competitor 2 URLs after loading config: {config.get('2competitor_urls', [])}")
    logging.info(f"Competitor 3 URLs after loading config: {config.get('3competitor_urls', [])}")
    logging.info(f"Variation URLs for competitor 1 (Merino Protect): {config.get('1variation_urls', [])}")
    logging.info(f"Variation URLs for competitor 2 (METARINO): {config.get('2variation_urls', [])}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram –±–æ—Ç–∞
    telegram_bot_token = config.get('telegram_bot_token', '')
    telegram_chat_id = config.get('telegram_chat_id', '')
    if not telegram_bot_token or not telegram_chat_id:
        logging.critical("Telegram bot token –∏–ª–∏ chat_id –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.")
        return
    bot = telebot.TeleBot(telegram_bot_token)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ URL-–∞–¥—Ä–µ—Å–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏ –≤–∞—Ä–∏–∞—Ü–∏–π
    PRODUCT_URLS = config.get('product_urls', [])
    VARIATION_URLS = config.get('variation_urls', [])

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏ –≤–∞—Ä–∏–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    COMPETITOR_URLS = {
        "Merino Protect": config.get('1competitor_urls', []),
        "METARINO": config.get('2competitor_urls', []),
    }

    COMPETITOR_VARIATION_URLS = {
        "Merino Protect": config.get('1variation_urls', []),
        "METARINO": config.get('2variation_urls', []),
    }

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥—Ä—É–≥–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    BATCH_SIZE = config.get('batch_size', 100)
    MIN_ACCEPTABLE_RATING = config.get('min_acceptable_rating', 4.0)
    PRICE_CHANGE_THRESHOLD = config.get('price_change_threshold', 5.0)
    COUPON_THRESHOLD = config.get('coupon_threshold', 10.0)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    update_hour = config.get('update_time_hour', 0)
    update_minute = config.get('update_time_minute', 0)
    timezone_str = config.get('timezone', 'Europe/Kiev')

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    active_trade_slots = config.get('active_trade_slots', ["14:00", "16:00", "18:00", "20:00", "22:00", "00:00", "02:00", "04:00", "06:00"])
    analysis_slots = config.get('analysis_slots', ["08:00", "10:00", "12:00"])

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    update_time_slot = f"{int(update_hour):02d}:{int(update_minute):02d}"
    all_slots = active_trade_slots + analysis_slots + [update_time_slot]

    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    all_slots = sorted(list(set(all_slots)))

    logging.info(f"–í—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ª–æ—Ç—ã: {all_slots}")

    # #### –¢–ï–°–¢–û–í–ê–Ø –í–ï–†–°–ò–Ø –¶–ò–ö–õ–ê: –ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ ####
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
        current_time = get_kyiv_time(timezone_str)
        logging.info(f"–¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å–ª–æ—Ç –∫–∞–∫ –±–ª–∏–∂–∞–π—à–∏–π —Å–ª–æ—Ç (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è)
        nearest_slot = get_next_slot(current_time, all_slots, timezone_str)
        logging.info(f"–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Å–ª–æ—Ç–∞: {nearest_slot.strftime('%H:%M')}")

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        current_results = gather_product_data(config, COMPETITOR_URLS, COMPETITOR_VARIATION_URLS)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Google Sheets
        update_google_sheets(
            current_results,
            spreadsheet_id,
            config,
            nearest_slot.strftime('%Y-%m-%d %H:%M:%S'),
            credentials_file
        )

        # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ Telegram
        if current_results:
            send_telegram_notification(
                config,
                nearest_slot.strftime('%Y-%m-%d %H:%M:%S'),
                current_results
            )

        logging.info(f"–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è —Å–ª–æ—Ç–∞ {nearest_slot.strftime('%H:%M')} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω.")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–æ–≤–æ–º –∑–∞–ø—É—Å–∫–µ –ø—Ä–æ—Ü–µ—Å—Å–∞: {e}")

    # #### –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¶–ò–ö–õ: –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –ó–∞–ø—É—Å–∫–∏ ####
    while True:
        try:
            current_time = get_kyiv_time(timezone_str)
            logging.info(f"–¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ—Ç–∞
            next_slot_time = get_next_slot(current_time, all_slots, timezone_str)
            logging.info(f"–°–ª–µ–¥—É—é—â–∏–π —Å–ª–æ—Ç: {next_slot_time.strftime('%Y-%m-%d %H:%M')}")

            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ—Ç–∞
            time_to_wait = (next_slot_time - current_time).total_seconds()

            if time_to_wait > 0:
                logging.info(f"–ñ–¥–µ–º {time_to_wait / 60:.2f} –º–∏–Ω—É—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ—Ç–∞.")
                time.sleep(time_to_wait)

            # –ü–æ—Å–ª–µ –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É
            logging.info(f"–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Å–ª–æ—Ç–∞: {next_slot_time.strftime('%H:%M')}")

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
            current_results = gather_product_data(config, COMPETITOR_URLS, COMPETITOR_VARIATION_URLS)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Google Sheets
            update_google_sheets(
                current_results,
                spreadsheet_id,
                config,
                next_slot_time.strftime('%Y-%m-%d %H:%M:%S'),
                credentials_file
            )

            # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ Telegram
            if current_results:
                send_telegram_notification(
                    config,
                    next_slot_time.strftime('%Y-%m-%d %H:%M:%S'),
                    current_results
                )

            logging.info(f"–ü—Ä–æ—Ü–µ—Å—Å –¥–ª—è —Å–ª–æ—Ç–∞ {next_slot_time.strftime('%H:%M')} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω.")

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
            time.sleep(60)  # –ñ–¥–µ–º –º–∏–Ω—É—Ç—É –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
    # #### –ö–û–ù–ï–¶ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û –¶–ò–ö–õ–ê ####


if __name__ == '__main__':
    main()
